{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlexNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"YDbAUs3uYEy5","outputId":"c9f3d2a3-0642-4d7c-9a76-8a0b65f2c23e","executionInfo":{"status":"ok","timestamp":1562758817309,"user_tz":-480,"elapsed":20133,"user":{"displayName":"施佑霖","photoUrl":"https://lh4.googleusercontent.com/-FoRsUBBPhQ8/AAAAAAAAAAI/AAAAAAAAAB0/chzOYAOiTWo/s64/photo.jpg","userId":"08729933880505161244"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QeO4e-DDrtJV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FJjM5Ei5n8sA-dQmZj_fqBK6eWWgqoZd"},"outputId":"b617017b-7eed-4d3c-a06f-8f7267d6e356","executionInfo":{"status":"ok","timestamp":1562758853714,"user_tz":-480,"elapsed":30090,"user":{"displayName":"施佑霖","photoUrl":"https://lh4.googleusercontent.com/-FoRsUBBPhQ8/AAAAAAAAAAI/AAAAAAAAAB0/chzOYAOiTWo/s64/photo.jpg","userId":"08729933880505161244"}}},"source":["!unzip \"gdrive/My Drive/Colab Notebooks/summer/images.zip\""],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hr6uu3lMzh0M","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.python.training.moving_averages import assign_moving_average\n","import numpy as np\n","import os\n","import cv2\n","import numpy as np\n","import random as rn\n","import tensorflow as tf\n","import threading\n","import time\n","\n","global n_classes\n","n_classes = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wyEhNlDlzh0P","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"6cdcf4c7-0745-429d-8ca5-067fa53ed8a6","executionInfo":{"status":"ok","timestamp":1562758855132,"user_tz":-480,"elapsed":27787,"user":{"displayName":"施佑霖","photoUrl":"https://lh4.googleusercontent.com/-FoRsUBBPhQ8/AAAAAAAAAAI/AAAAAAAAAB0/chzOYAOiTWo/s64/photo.jpg","userId":"08729933880505161244"}}},"source":["_weights = {\n","        'wc1': tf.get_variable(\"wc1\", [7, 7, 3, 96], initializer=tf.glorot_uniform_initializer()),\n","        'wc2': tf.get_variable('wc2',[5, 5, 96, 256], initializer=tf.glorot_uniform_initializer()),\n","        'wc3': tf.get_variable('wc3',[3, 3, 256, 384], initializer=tf.glorot_uniform_initializer()),\n","        'wc4': tf.get_variable('wc4',[3, 3, 384, 384], initializer=tf.glorot_uniform_initializer()),\n","        'wc5': tf.get_variable('wc5',[3, 3, 384, 256], initializer=tf.glorot_uniform_initializer()),\n","        'wd2': tf.get_variable('wd2',[4096, 4096], initializer=tf.glorot_uniform_initializer()),\n","        'out': tf.get_variable('out',[4096, n_classes], initializer=tf.glorot_uniform_initializer())\n","    }\n","_biases = {\n","        'bc1': tf.get_variable('bc1',[96], initializer=tf.glorot_uniform_initializer()),\n","        'bc2': tf.get_variable('bc2',[256], initializer=tf.glorot_uniform_initializer()),\n","        'bc3': tf.get_variable('bc3',[384], initializer=tf.glorot_uniform_initializer()),\n","        'bc4': tf.get_variable('bc4',[384], initializer=tf.glorot_uniform_initializer()),\n","        'bc5': tf.get_variable('bc5',[256], initializer=tf.glorot_uniform_initializer()),\n","        'bd2': tf.get_variable('db2',[4096], initializer=tf.glorot_uniform_initializer()),\n","        'out': tf.get_variable('bout',[n_classes], initializer=tf.glorot_uniform_initializer())\n","    }"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0710 11:40:55.827053 140340629251968 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z-Oekfd9zh0Q","colab":{}},"source":["def activation(x,name=\"activation\"):\n","    return tf.nn.relu(x, name=name)\n","    \n","def conv2d(name, l_input, w, b, s, p, scope):\n","    l_input = tf.nn.conv2d(l_input, w, strides=[1,s,s,1], padding=p, name=name)\n","    l_input = activation(l_input+b)\n","    \n","    return l_input\n","\n","def max_pool(name, l_input, k, s):\n","    return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding='VALID', name=name)\n","\n","def norm(l_input, lsize=4, name=\"lrn\"):\n","    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"94VSiHqhzh0S","colab":{}},"source":["   \n","def alex_net(_X, _dropout, batch_size):\n","    conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'], 3, 'VALID', 'conv1')\n","    pool1 = max_pool('pool1', conv1, k=3,s=2)\n","    conv2 = conv2d('conv2', pool1, _weights['wc2'], _biases['bc2'], 1, 'SAME', 'conv2')\n","    pool2 = max_pool('pool2', conv2, k=3,s=2)\n","    conv3 = conv2d('conv3', pool2, _weights['wc3'], _biases['bc3'], 1, 'SAME', 'conv3')\n","    conv4 = conv2d('conv4', conv3, _weights['wc4'], _biases['bc4'], 1, 'SAME', 'conv4')\n","    conv5 = conv2d('conv5', conv4, _weights['wc5'], _biases['bc5'], 1, 'SAME', 'conv5')\n","    pool5 = max_pool('pool2', conv5, k=3,s=2)\n","    # Find current size of conv5 to fit the requirement of FC1.\n","    sizes = pool5.get_shape().as_list()\n","    neurons =  sizes[1]*sizes[2]*sizes[3]\n","    dense1 = tf.reshape(pool5, [batch_size, neurons]) # Reshape conv5 output to fit dense layer input\n","    wei_den1 = tf.get_variable('wd3',[neurons, 4096], initializer=tf.glorot_uniform_initializer())\n","    b_den1 =  tf.get_variable('wd4',[4096], initializer=tf.glorot_uniform_initializer())\n","    \n","    dense1 = activation(tf.matmul(dense1, wei_den1) + b_den1, name='fc1') # Relu activation\n","    dd1=tf.nn.dropout(dense1, _dropout)\n","    dense2 = activation(tf.matmul(dd1, _weights['wd2']) + _biases['bd2'], name='fc2') # Relu activation\n","    out = tf.matmul(dense2, _weights['out']) + _biases['out'] # Relu activation\n","\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tCNUC9U1zh0U","colab":{}},"source":["#==========================================================================\n","#=============Reading data in multithreading manner========================\n","#==========================================================================\n","def read_labeled_image_list(image_list_file, training_img_dir):\n","    \"\"\"Reads a .txt file containing pathes and labeles\n","    Args:\n","       image_list_file: a .txt file with one /path/to/image per line\n","       label: optionally, if set label will be pasted after each line\n","    Returns:\n","       List with all filenames in file image_list_file\n","    \"\"\"\n","    f = open(image_list_file, 'r')\n","    filenames = []\n","    labels = []\n","\n","    for line in f:\n","        filename, label = line[:-1].split(' ')\n","        filename = training_img_dir+filename\n","        filenames.append(filename)\n","        labels.append(int(label))\n","        \n","    return filenames, labels\n","    \n","    \n","def read_images_from_disk(input_queue, size1=256):\n","    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n","    Args:\n","      filename_and_label_tensor: A scalar string tensor.\n","    Returns:\n","      Two tensors: the decoded image, and the string label.\n","    \"\"\"\n","    label = input_queue[1]\n","    fn=input_queue[0]\n","    file_contents = tf.read_file(input_queue[0])\n","    example = tf.image.decode_jpeg(file_contents, channels=3)\n","    \n","    #example = tf.image.decode_png(file_contents, channels=3, name=\"dataset_image\") # png fo rlfw\n","    example=tf.image.resize_images(example, [size1,size1])\n","    return example, label, fn\n","    \n","def setup_inputs(sess, filenames, training_img_dir, image_size=256, crop_size=224, isTest=False, batch_size=128):\n","    \n","    # Read each image file\n","    image_list, label_list = read_labeled_image_list(filenames, training_img_dir)\n","\n","    images = tf.cast(image_list, tf.string)\n","    labels = tf.cast(label_list, tf.int64)\n","     # Makes an input queue\n","    if isTest is False:\n","        isShuffle = True\n","    else:\n","        isShuffle = False\n","        \n","    input_queue = tf.train.slice_input_producer([images, labels], shuffle=isShuffle)\n","    image, y,fn = read_images_from_disk(input_queue)\n","\n","    channels = 3\n","    image.set_shape([None, None, channels])\n","        \n","    # Crop and other random augmentations\n","    if isTest is False:\n","        image = tf.image.random_flip_left_right(image)\n","        image = tf.image.random_saturation(image, .95, 1.05)\n","        image = tf.image.random_brightness(image, .05)\n","        image = tf.image.random_contrast(image, .95, 1.05)\n","        \n","\n","    image = tf.random_crop(image, [crop_size, crop_size, 3])\n","    image = tf.cast(image, tf.float32)/255.0\n","    \n","    image, y,fn = tf.train.batch([image, y, fn], batch_size=batch_size, capacity=4,name='labels_and_images')\n","\n","    tf.train.start_queue_runners(sess=sess)\n","\n","    return image, y, fn, len(label_list)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h7AtFd4czh0W","colab":{}},"source":["# Training setting\n","batch_size = 128 \n","display_step = 80\n","dropout = 0.5# Dropout rate\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7LCc7xsQzh0Y","outputId":"14fe9474-3019-4d17-dfc2-433c6d581b98","colab":{"base_uri":"https://localhost:8080/","height":581},"executionInfo":{"status":"ok","timestamp":1562758858475,"user_tz":-480,"elapsed":23107,"user":{"displayName":"施佑霖","photoUrl":"https://lh4.googleusercontent.com/-FoRsUBBPhQ8/AAAAAAAAAAI/AAAAAAAAAB0/chzOYAOiTWo/s64/photo.jpg","userId":"08729933880505161244"}}},"source":["keep_prob = tf.placeholder(tf.float32)          # Dropout rate to be fed\n","learning_rate = tf.placeholder(tf.float32)      # Learning rate to be fed\n","lr = 1e-3                                   # Learning rate start\n","\n","# Setup the tensorflow...\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.Session(config=config)\n","\n","print(\"Preparing the training & validation data...\")\n","train_data, train_labels, filelist1, glen1 = setup_inputs(sess, \"train.txt\", \"./\", batch_size=batch_size)\n","val_data, val_labels, filelist2, tlen1 = setup_inputs(sess, \"val.txt\", \"./\", batch_size=batch_size)\n","\n","max_iter = glen1*100\n","\n","print(\"Preparing the training model with learning rate = %.5f...\" % (lr))\n","\n","with tf.variable_scope(\"alexnet\", reuse=tf.AUTO_REUSE) as scope:\n","    pred = alex_net(train_data,keep_prob,batch_size)\n","\n","with tf.name_scope('Loss_and_Accuracy'):\n","  cost = tf.losses.sparse_softmax_cross_entropy(labels=train_labels, logits=pred)\n","  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n","  correct_prediction = tf.equal(tf.argmax(pred, 1), train_labels)\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  top5=tf.reduce_mean(tf.cast(tf.nn.in_top_k(pred, train_labels, 5), tf.float32))\n","  \n","  tf.summary.scalar('Loss', cost)\n","  tf.summary.scalar('Training_Accuracy', accuracy)\n","  tf.summary.scalar('Top-5_accuracy', top5)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Preparing the training & validation data...\n"],"name":"stdout"},{"output_type":"stream","text":["W0710 11:40:57.945866 140340629251968 deprecation.py:323] From <ipython-input-7-b45acdff6d74>:51: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0710 11:40:57.955920 140340629251968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0710 11:40:57.976156 140340629251968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0710 11:40:57.980314 140340629251968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n","W0710 11:40:57.984625 140340629251968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0710 11:40:57.989996 140340629251968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0710 11:40:58.041692 140340629251968 deprecation.py:323] From <ipython-input-7-b45acdff6d74>:68: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n","W0710 11:40:58.052447 140340629251968 deprecation.py:323] From <ipython-input-7-b45acdff6d74>:70: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n"],"name":"stderr"},{"output_type":"stream","text":["Preparing the training model with learning rate = 0.00100...\n"],"name":"stdout"},{"output_type":"stream","text":["W0710 11:40:58.564862 140340629251968 deprecation.py:506] From <ipython-input-6-5f240c5a2da9>:19: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0710 11:40:58.602788 140340629251968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3CGfQ_Cbzh0c","outputId":"764f25bf-b136-41f4-9b4c-8b6f4998a831","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","sess.run(init)\n","step = 0\n","writer = tf.summary.FileWriter(\"/tmp/log2\", sess.graph)\n","summaries = tf.summary.merge_all()\n","\n","print(\"We are going to train the ImageNet model based on AlexNet!!!\")\n","while (step * batch_size) < max_iter:\n","    epoch1=np.floor((step*batch_size)/glen1)\n","    if (((step*batch_size)%glen1 < batch_size) & (lr==1e-3) & (epoch1 >2)):\n","        lr /= 10\n","\n","    sess.run(optimizer,  feed_dict={keep_prob: dropout, learning_rate: lr})\n","\n","    if (step % 15000==1) & (step>15000):\n","        save_path = saver.save(sess, \"checkpoint/tf_alex_model_iter\" + str(step) + \".ckpt\")\n","        print(\"Model saved in file at iteration %d: %s\" % (step*batch_size,save_path))\n","\n","    if step % display_step == 1:\n","        # calculate the loss\n","        loss, acc, top5acc, summaries_string = sess.run([cost, accuracy, top5, summaries], feed_dict={keep_prob: 1.})\n","        print(\"Iter=%d/epoch=%d, Loss=%.6f, Training Accuracy=%.6f, Top-5 Accuracy=%.6f, lr=%f\" % (step*batch_size, epoch1 ,loss, acc, top5acc, lr))\n","        writer.add_summary(summaries_string, step)\n","\n","\n","    step += 1\n","print(\"Optimization Finished!\")\n","save_path = saver.save(sess, \"checkpoint/tf_alex_model.ckpt\")\n","print(\"Model saved in file: %s\" % save_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["We are going to train the ImageNet model based on AlexNet!!!\n","Iter=128/epoch=0, Loss=4.349505, Training Accuracy=0.007812, Top-5 Accuracy=0.148438, lr=0.001000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jtfg_YheLPwF","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AOQOeejKzh0f","colab":{}},"source":["exit()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sr0obIo2zh0g","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}